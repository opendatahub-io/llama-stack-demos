kind: Deployment
apiVersion: apps/v1
metadata:
  name: llama31-70b
  labels:
    app: llama31-70b
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama31-70b
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: llama31-70b
    spec:
      volumes:
        - name: hf-cache
          emptyDir: {}
        - name: triton
          emptyDir: {}
        - name: chat-template
          configMap:
            name: llama31-70-template
            defaultMode: 420
        - name: config
          emptyDir: {}
      containers:
        - resources:
            limits:
              nvidia.com/gpu: '4'
          terminationMessagePath: /dev/termination-log
          name: llama31-70b
          env:
            - name: VLLM_PORT
              value: '8000'
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: huggingface-secret
                  key: HF_TOKEN
          ports:
            - containerPort: 8000
              protocol: TCP
          imagePullPolicy: Always
          volumeMounts:
            - name: hf-cache
              mountPath: /.cache
            - name: triton
              mountPath: /.triton
            - name: chat-template
              mountPath: /app
            - name: config
              mountPath: /.config
          terminationMessagePolicy: File
          image: 'vllm/vllm-openai:v0.7.3'
          args:
            - --model
            - meta-llama/Llama-3.1-70B-Instruct
            - --tensor-parallel-size
            - "4"  # Use all 4 A100 GPUs
            - --gpu-memory-utilization
            - "0.95"  # Prevent OOM errors
            - --quantization
            - "fp8"
            - --max-num-batched-tokens
            - "4096"  # Control memory usage
            - --enable-auto-tool-choice  # Keeping your tool settings
            - --chat-template
            - /app/tool_chat_template_llama3.1_json.jinja
            - --tool-call-parser
            - llama3_json
            - --port
            - "8000"
            - --swap-space
            - "32"
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
      securityContext: {}
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
